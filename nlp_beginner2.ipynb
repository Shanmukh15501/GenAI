{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How Deep Learning Enhances NLP:\n",
    "\n",
    "- Deep learning, a subset of machine learning, uses artificial neural networks to learn complex patterns from data.\n",
    "- When applied to NLP, deep learning models can automatically learn linguistic features from raw text, eliminating the need for manual feature engineering.\n",
    "- This has led to significant improvements in NLP tasks such as:\n",
    "\n",
    "- Machine translation: Translating text from one language to another.\n",
    "- Sentiment analysis: Determining the emotional tone of text.\n",
    "- Text summarization: Generating concise summaries of long documents.\n",
    "- Question answering: Enabling machines to answer questions based on given text.\n",
    "- Named entity recognition: Identifying and classifying named entities in text (e.g., people, organizations, locations).\n",
    "\n",
    "\n",
    "# Key Deep Learning Architectures in NLP:\n",
    "\n",
    "## Artificial Neural Networks (ANNs):\n",
    "### General Purpose:\n",
    "- ANNs are foundational neural network structures. They are versatile and can be applied to various tasks.\n",
    "- They consist of interconnected layers of neurons, with each neuron connected to every neuron in the adjacent layers (fully connected).\n",
    "- Data Handling:\n",
    "    ANNs can handle structured data, such as tabular data, numerical data, and categorical data.\n",
    "### Applications:\n",
    "- They are used for tasks like:\n",
    "- Regression (predicting numerical values).\n",
    "- Classification (categorizing data).\n",
    "- Pattern recognition.\n",
    "## Recurrent Neural Networks (RNNs):\n",
    "- Designed to handle sequential data, making them suitable for processing text.\n",
    "- Especially useful for tasks like language modeling and machine translation.\n",
    "## Convolutional Neural Networks (CNNs):\n",
    "- Effective for capturing local patterns in text, such as phrases and n-grams.\n",
    "- Used in tasks like text classification and sentiment analysis.\n",
    "## Transformers:\n",
    "- A revolutionary architecture that uses self-attention mechanisms to capture long-range dependencies in text.\n",
    "Has led to significant breakthroughs in NLP, with models like BERT and GPT achieving state-of-the-art results on various tasks.\n",
    "Transformers are the base architecture that many Large Language Models are built upon."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
