{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agents\n",
    "- In LangChain, agents are systems that autonomously decide how to use tools to accomplish a task. They take an input, analyze it, and choose the right tool(s) to solve the problem.\n",
    "- Types of Agents in LangChain:\n",
    "# Zero-shot Agent:\n",
    "\n",
    "- Does not rely on prior training or a pre-defined plan.\n",
    "  Decides what to do based on the current input alone.\n",
    "  \n",
    "# Self-Ask Agent:\n",
    "\n",
    "- Asks clarifying questions if needed before selecting a tool or performing an action.\n",
    "  It’s like a problem solver that seeks more info to make better decisions.\n",
    "\n",
    "# React Agent:\n",
    "\n",
    "- Reacts based on the outcome of the previous tool or action.\n",
    "  It adapts its next step depending on the result of its earlier choices.\n",
    "\n",
    "# Agent with Memory:\n",
    "\n",
    "- Remembers past interactions or decisions, which helps it make more informed choices in the future.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Zero-shot Agent\n",
    "- Example:\n",
    "    You ask, \"What's the weather today in New York?\"\n",
    "    The zero-shot agent immediately chooses a weather API and calls it to get the answer without asking any questions or needing extra context.\n",
    "\n",
    "# 2. Self-Ask Agent\n",
    "-   Example:\n",
    "    You ask, \"Who won the last World Cup?\"\n",
    "\n",
    "    The agent first asks, \"Which year are you referring to?\" (since there have been multiple World Cups).\n",
    "    Once the user provides the year, it fetches the correct result from the web or database.\n",
    "\n",
    "# 3. React Agent\n",
    "-   Example:\n",
    "    You ask, \"Translate 'Bonjour' to English.\"\n",
    "\n",
    "    The agent uses a translation tool and gets the result \"Hello.\"\n",
    "    If the user then asks, \"What language is that?\", the agent can use another tool to identify the language and respond \"French.\"\n",
    "\n",
    "# 4. Agent with Memory\n",
    "-   Example:\n",
    "    You ask, \"What’s my schedule for today?\"\n",
    "\n",
    "    The agent retrieves your calendar from a tool and lists your meetings.\n",
    "    The next time you ask about your schedule, the agent remembers your previous meetings and can refer to them while answering new questions.\n",
    "    In each case, the agent is smart enough to decide how to use tools and adapt based on the input or previous interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zero Shot Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Adari Shanmukh\\AppData\\Local\\Temp\\ipykernel_1020\\2593219042.py:6: LangChainDeprecationWarning: The class `OpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAI``.\n",
      "  llm = OpenAI(temperature=0)\n",
      "C:\\Users\\Adari Shanmukh\\AppData\\Local\\Temp\\ipykernel_1020\\2593219042.py:23: LangChainDeprecationWarning: LangChain agents will continue to be supported, but it is recommended for new use cases to be built with LangGraph. LangGraph offers a more flexible and full-featured framework for building agents, including support for tool-calling, persistence of state, and human-in-the-loop workflows. For details, refer to the `LangGraph documentation <https://langchain-ai.github.io/langgraph/>`_ as well as guides for `Migrating from AgentExecutor <https://python.langchain.com/docs/how_to/migrate_agent/>`_ and LangGraph's `Pre-built ReAct agent <https://langchain-ai.github.io/langgraph/how-tos/create-react-agent/>`_.\n",
      "  agent = initialize_agent(\n",
      "C:\\Users\\Adari Shanmukh\\AppData\\Local\\Temp\\ipykernel_1020\\2593219042.py:32: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  response = agent.run(query)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I should use a calculator to perform the mathematical operation.\n",
      "Action: Calculator\n",
      "Action Input: 2+2\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3m4\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer.\n",
      "Final Answer: 4\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import initialize_agent, Tool, AgentType\n",
    "from langchain.agents import create_openai_functions_agent\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "# Initialize the language model (OpenAI GPT)\n",
    "llm = OpenAI(temperature=0)\n",
    "\n",
    "# Create some sample tools (you can replace these with actual tools like APIs or databases)\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"Search\",\n",
    "        func=lambda x: f\"Searching for {x}\",  # Dummy function for illustration\n",
    "        description=\"A tool to search for information\"\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"Calculator\",\n",
    "        func=lambda x: eval(x),  # Basic calculator tool\n",
    "        description=\"A tool to perform mathematical operations\"\n",
    "    ),\n",
    "]\n",
    "\n",
    "# Initialize the zero-shot agent\n",
    "agent = initialize_agent(\n",
    "    tools,\n",
    "    llm,\n",
    "    agent_type=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Example task: Using the zero-shot agent to handle a question\n",
    "query  = \"What is 2+2\"\n",
    "response = agent.run(query)\n",
    "\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I should use the Search tool to find the answer\n",
      "Action: Search\n",
      "Action Input: 'Who won last world cup'\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3msnippet: The FIFA World Cup, often called the World Cup, is an international association football competition among the senior men's national teams of the members of the Fédération Internationale de Football Association (), the sport's global governing body.The tournament has been held every four years since the inaugural tournament in 1930, with the exception of 1942 and 1946 due to the Second World ..., title: FIFA World Cup - Wikipedia, link: https://en.wikipedia.org/wiki/FIFA_World_Cup, snippet: FIFA(Federation Internationale de Football Association) is the worldwide governing organization of football. The FIFA World Cup started in 1930 and is held every four years. 32 teams qualified for the last FIFA World Cup. It is one of the biggest sporting events in the world watched by billions of people. Uruguay won the first edition of the FIFA World Cup and as of now, Argentina won the last ..., title: FIFA World Cup Winners List(1930 - GeeksforGeeks, link: https://www.geeksforgeeks.org/fifa-world-cup-winners-list/, snippet: The FIFA World Cup 26 will be the 23rd edition of the tournament but the first to feature 48 teams and three host countries: Canada, Mexico, and the USA.. The 2022 FIFA World Cup is the 22nd football World Cup organized in Qatar. A total of 32 teams participated in FIFA's tournament. Argentina won the 2022 FIFA World Cup on 18th December 2022 after beating defending champions France 4-2 on ..., title: FIFA World Cup Winners: All time World Cup Winners List, link: https://www.fifaworldcupnews.com/fifa-world-cup-winner-all-time-world-cup-winners-list/, snippet: This is a complete list of all the FIFA World Cup winners since its start in 1930. Find out who won the first and latest World Cup. Complete FIFA World Cup Winners List: Every Winner Since 1930, title: Complete FIFA World Cup Winners List: Every Winner Since 1930, link: https://soccermavericks.com/fifa-world-cup-winners-list/\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: The last team to win the FIFA World Cup was Argentina in 2022.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "The last team to win the FIFA World Cup was Argentina in 2022.\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import initialize_agent, Tool, AgentType\n",
    "\n",
    "from langchain.agents import self_ask_with_search\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.agents import create_openai_functions_agent\n",
    "from langchain.tools import DuckDuckGoSearchResults\n",
    "\n",
    "# Initialize the language model (e.g., OpenAI GPT)\n",
    "llm = OpenAI(temperature=0)\n",
    "\n",
    "# Set up a search tool (using DuckDuckGo search)\n",
    "search_tool = DuckDuckGoSearchResults()\n",
    "\n",
    "# Define a self-ask agent with search\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"Search\",\n",
    "        func=search_tool.run,  # DuckDuckGo search function\n",
    "        description=\"Search the web for information.\"\n",
    "    ),\n",
    "]\n",
    "\n",
    "\n",
    "# Initialize the Self-Ask Agent (with search)\n",
    "agent = initialize_agent(tools, llm, verbose=True, agent_type=\"self-ask-with-search\")\n",
    "\n",
    "# Example task: ask the agent about a complex topic\n",
    "query = \"Who won last world cup\"\n",
    "\n",
    "# Run the agent\n",
    "response = agent.run(query)\n",
    "\n",
    "# Print the result\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.agents import tool\n",
    "\n",
    "\n",
    "@tool\n",
    "def get_word_length(word: str) -> int:\n",
    "    \"\"\"Returns the length of a word.\"\"\"\n",
    "    return len(word)\n",
    "\n",
    "\n",
    "get_word_length.invoke(\"abc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[StructuredTool(name='get_word_length', description='Returns the length of a word.', args_schema=<class 'langchain_core.utils.pydantic.get_word_length'>, func=<function get_word_length at 0x0000012F38A66A20>)]\n"
     ]
    }
   ],
   "source": [
    "tools = [get_word_length]\n",
    "print(tools)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI need to find out the current time.  \n",
      "Action: Time  \n",
      "Action Input: None  \u001b[0m\u001b[36;1m\u001b[1;3m02:49 PM\u001b[0m\u001b[32;1m\u001b[1;3mI now know the final answer.  \n",
      "Final Answer: The current time is 02:49 PM.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "response: {'input': 'What time is it?', 'output': 'The current time is 02:49 PM.'}\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain import hub\n",
    "from langchain.agents import (\n",
    "    AgentExecutor,\n",
    "    create_react_agent,\n",
    ")\n",
    "from langchain_core.tools import Tool\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "#https://medium.com/@shravankoninti/agent-tools-basic-code-using-langchain-50e13eb07d92\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "# Define a very simple tool function that returns the current time\n",
    "def get_current_time(*args, **kwargs):\n",
    "    \"\"\"Returns the current time in H:MM AM/PM format.\"\"\"\n",
    "    import datetime  # Import datetime module to get current time\n",
    "\n",
    "    now = datetime.datetime.now()  # Get current time\n",
    "    return now.strftime(\"%I:%M %p\")  # Format time in H:MM AM/PM format\n",
    "\n",
    "\n",
    "# List of tools available to the agent\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"Time\",  # Name of the tool\n",
    "        func=get_current_time,  # Function that the tool will execute\n",
    "        # Description of the tool\n",
    "        description=\"Useful for when you need to know the current time\",\n",
    "    ),\n",
    "]\n",
    "\n",
    "# Pull the prompt template from the hub\n",
    "# ReAct = Reason and Action\n",
    "# https://smith.langchain.com/hub/hwchase17/react\n",
    "prompt = hub.pull(\"hwchase17/react\")\n",
    "\n",
    "# Initialize a ChatOpenAI model\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\", temperature=0\n",
    ")\n",
    "\n",
    "# Create the ReAct agent using the create_react_agent function\n",
    "agent = create_react_agent(\n",
    "    llm=llm,\n",
    "    tools=tools,\n",
    "    prompt=prompt,\n",
    "    stop_sequence=True,\n",
    ")\n",
    "\n",
    "# Create an agent executor from the agent and tools\n",
    "agent_executor = AgentExecutor.from_agent_and_tools(\n",
    "    agent=agent,\n",
    "    tools=tools,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "# Run the agent with a test query\n",
    "response = agent_executor.invoke({\"input\": \"What time is it?\"})\n",
    "\n",
    "# Print the response from the agent\n",
    "print(\"response:\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Adari Shanmukh\\AppData\\Local\\Temp\\ipykernel_14900\\2044509963.py:12: LangChainDeprecationWarning: The class `OpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAI``.\n",
      "  llm = OpenAI(temperature=0)\n",
      "C:\\Users\\Adari Shanmukh\\AppData\\Local\\Temp\\ipykernel_14900\\2044509963.py:13: LangChainDeprecationWarning: LangChain agents will continue to be supported, but it is recommended for new use cases to be built with LangGraph. LangGraph offers a more flexible and full-featured framework for building agents, including support for tool-calling, persistence of state, and human-in-the-loop workflows. For details, refer to the `LangGraph documentation <https://langchain-ai.github.io/langgraph/>`_ as well as guides for `Migrating from AgentExecutor <https://python.langchain.com/docs/how_to/migrate_agent/>`_ and LangGraph's `Pre-built ReAct agent <https://langchain-ai.github.io/langgraph/how-tos/create-react-agent/>`_.\n",
      "  agent = initialize_agent(tools, llm, agent_type=\"zero-shot-react-description\")\n",
      "C:\\Users\\Adari Shanmukh\\AppData\\Local\\Temp\\ipykernel_14900\\2044509963.py:16: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  result = agent.run(\"What's the weather like in Paris?\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The weather in Paris is sunny and warm.\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import initialize_agent, Tool\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "# Define a simple tool\n",
    "def get_weather(city: str) -> str:\n",
    "    return f\"The weather in {city} is sunny and warm.\"\n",
    "\n",
    "tools = [\n",
    "    Tool(name=\"Weather Info\", func=get_weather, description=\"Provides the weather information of a city\")\n",
    "]\n",
    "\n",
    "llm = OpenAI(temperature=0)\n",
    "agent = initialize_agent(tools, llm, agent_type=\"zero-shot-react-description\")\n",
    "\n",
    "# Test the agent\n",
    "result = agent.run(\"What's the weather like in Paris?\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'create_conversational_agent' from 'langchain.agents' (d:\\GenAI\\venv\\Lib\\site-packages\\langchain\\agents\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01magents\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m create_conversational_agent, Tool\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllms\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m OpenAI\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcheck_order_status\u001b[39m(order_id: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'create_conversational_agent' from 'langchain.agents' (d:\\GenAI\\venv\\Lib\\site-packages\\langchain\\agents\\__init__.py)"
     ]
    }
   ],
   "source": [
    "from langchain.agents import create_conversational_agent, Tool\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "def check_order_status(order_id: str) -> str:\n",
    "    return f\"Order {order_id} is in transit.\"\n",
    "\n",
    "tools = [\n",
    "    Tool(name=\"Order Status Checker\", func=check_order_status, description=\"Checks the status of an order.\")\n",
    "]\n",
    "\n",
    "llm = OpenAI(temperature=0.7)\n",
    "agent = create_conversational_agent(tools, llm)\n",
    "\n",
    "# Simulating conversation\n",
    "agent_memory = {}\n",
    "agent.run(\"I would like to check the status of order #12345\", memory=agent_memory)\n",
    "agent.run(\"Can you remind me what my last query was?\", memory=agent_memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
