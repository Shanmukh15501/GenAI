{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Groq is a company that develops high-performance hardware and software solutions for AI inference. Their core product, the LPU™   Inference Engine, is designed to accelerate AI tasks, offering significant speed improvements. It provides superior compute power, enabling faster processing of AI models. The platform is optimized for energy efficiency, reducing operational costs. Overall, Groq aims to enhance AI performance across various applications, including machine learning and deep learning workloads.\n",
    "- https://console.groq.com/playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import openai\n",
    "load_dotenv()\n",
    "\n",
    "openai.api_key=os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "groq_api_key=os.getenv('GROQ_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "groq_model = ChatGroq(model=\"gemma2-9b-it\",groq_api_key=groq_api_key)\n",
    "openai_model = ChatOpenAI(model=\"gpt-4o\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='नमस्ते, आप कैसे हैं? \\n\\n(Namaste, aap kaise hain?) \\n' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 24, 'prompt_tokens': 18, 'total_tokens': 42, 'completion_time': 0.043636364, 'prompt_time': 7.593e-05, 'queue_time': 0.020824519000000003, 'total_time': 0.043712294}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None} id='run-5cd4fc59-ba81-4f36-9ab3-ffac1c4ac544-0' usage_metadata={'input_tokens': 18, 'output_tokens': 24, 'total_tokens': 42}\n",
      "\n",
      "\n",
      "\n",
      "content='नमस्ते, आप कैसे हैं?' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 20, 'total_tokens': 30, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_4691090a87', 'finish_reason': 'stop', 'logprobs': None} id='run-659195a6-b9a9-464a-8227-3bc6bb7d03d4-0' usage_metadata={'input_tokens': 20, 'output_tokens': 10, 'total_tokens': 30, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import SystemMessage,AIMessage,HumanMessage\n",
    "\n",
    "message = [\n",
    "        SystemMessage(\"Translate from English to Hindi\"),\n",
    "        HumanMessage(content=\"Hello how are you\")\n",
    "]\n",
    "\n",
    "response1 = groq_model.invoke(message)\n",
    "response2 = openai_model.invoke(message)\n",
    "\n",
    "print(response1)\n",
    "print(\"\\n\"*2)\n",
    "print(response2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'नमस्ते, आप कैसे हैं? \\n\\n(Namaste, aap kaise hain?) \\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "parser = StrOutputParser()\n",
    "\n",
    "parser.invoke(response1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using LCEL we can chain the components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "नमस्ते, आप कैसे हैं? (Namaste, aap kaise hain?) \n",
      "\n",
      "नमस्ते, आप कैसे हैं?\n"
     ]
    }
   ],
   "source": [
    "chain1= groq_model|parser\n",
    "print(chain1.invoke(message))\n",
    "\n",
    "chain2= openai_model|parser\n",
    "print(chain2.invoke(message))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'नमस्ते, मैं शंमुख हूँ। \\n\\n(Namaste, main Shanmukha hoon.)\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#another efficient method is using prompt templates\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "generic_prompt = \"Translate into following {language}\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([(\"system\",generic_prompt),(\"user\",\"{text}\")])\n",
    "\n",
    "prompt.invoke({\"language\":\"Hindi\",\"text\":\"Hello this is shanmukh\"})\n",
    "\n",
    "chain3 = prompt | groq_model | parser\n",
    "\n",
    "chain3.invoke({\"language\":\"Hindi\",\"text\":\"Hello this is shanmukh\"})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "virtualenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
